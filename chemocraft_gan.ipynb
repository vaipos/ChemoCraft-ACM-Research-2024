{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the GAN Architecture\n",
    "1. The Generator\n",
    "2. The Discriminator\n",
    "3. Connecting the Generator & Discriminator\n",
    "4. Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's output shape must be the same shape as the cropped real image: (210, 180, 1)\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "dim = 100\n",
    "\n",
    "def build_generator(latent_dim, output_shape=(210, 180, 1)):\n",
    "    model = models.Sequential(name=\"ChemoCraft_Generator\")\n",
    "    print(\"Building Generator\")\n",
    "\n",
    "    model.add(layers.Input(shape=(latent_dim,)))\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(256 * 32, activation=\"relu\"))\n",
    "    model.add(layers.Reshape(target_shape=(16, 16, 32)))\n",
    "    model.add(layers.Conv2DTranspose(filters=32, kernel_size=5, strides=6, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Conv2DTranspose(filters=8, kernel_size=3, strides=5, padding=\"same\", activation=\"relu\"))\n",
    "    \n",
    "    prev_out = model.layers[-1].output.shape\n",
    "\n",
    "    model.add(layers.Conv2D(1, kernel_size=(prev_out[1]-output_shape[0]+1, prev_out[2]-output_shape[1]+1), strides=1, padding=\"valid\", activation=\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "chemocraft_generator = build_generator(latent_dim=dim)\n",
    "chemocraft_generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator's input shape should be the same shape as the generator's output: (210, 180, 1)\n",
    "\n",
    "shape = (210, 180, 1)\n",
    "\n",
    "def build_discriminator(input_shape=shape):\n",
    "\n",
    "    model = models.Sequential(name=\"ChemoCraft_Discriminator\")\n",
    "    print(\"Building Discriminator Model\")\n",
    "\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=9, strides=5, padding=\"same\", activation=\"relu\")) \n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=5, strides=4, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=3, strides=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "    return model\n",
    "   \n",
    "chemocraft_discriminator = build_discriminator(shape)\n",
    "chemocraft_discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting Generator & Discriminator through the GAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_gan(generator, discriminator, latent_dim):\n",
    "    discriminator.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    z = layers.Input(shape=(latent_dim,))\n",
    "    img = generator(z)\n",
    "    discriminator.trainable = False\n",
    "    validity = discriminator(img)\n",
    "    gan = models.Model(z, validity)\n",
    "    gan.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return gan\n",
    "\n",
    "chemocraft_gan = compile_gan(chemocraft_generator, chemocraft_discriminator,latent_dim=dim)\n",
    "chemocraft_gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Data Pipeline for Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'chemocraft-data'\n",
    "folder_path = 'MICCAI_BraTS2020_TrainingData/'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "folder_path = 'tanmay/brain_slices/'\n",
    "\n",
    "keys = []\n",
    "\n",
    "for obj in bucket.objects.filter(Prefix=folder_path):\n",
    "    if obj.key.endswith('.png'):\n",
    "        sample_key = obj.key.split('/')[-3] # Getting the Brain numbers.\n",
    "        if sample_key not in keys:\n",
    "            keys.append(sample_key)\n",
    "\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "folder_path = 'tanmay/brain_slices/'\n",
    "\n",
    "def load_images(bucket_name, folder_path, folder_suffix):\n",
    "    directory = f\"{folder_path}{folder_suffix}/\"\n",
    "    print(f\"Loading images from S3 Bucket: {bucket_name}{directory}\")\n",
    "    images = []\n",
    "\n",
    "    for obj in bucket_name.objects.filter(Prefix=directory):\n",
    "        if obj.key.endswith('.png'):\n",
    "            try:\n",
    "                file_stream = io.BytesIO(obj.get()['Body'].read())\n",
    "                image = load_img(file_stream, target_size=(210, 180), color_mode='grayscale')\n",
    "                print(f\"Adding {obj.key.removeprefix(\"tanmay/brain_slices/\")} into an array.\")\n",
    "                image = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "                images.append(image)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {obj.key}: {e}\")\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "my_arr = load_images(bucket_name=bucket, folder_path=folder_path, folder_suffix=\"320/flair\") # Testing functionality on a small folder\n",
    "print(my_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def train_gan(generator, latent_dim, discriminator, gan, training_array, batch_size):\n",
    "    for _ in range(len(training_array) // batch_size):\n",
    "        # Select random batch of real images\n",
    "        idx = np.random.randint(0, len(training_array), batch_size)\n",
    "        real_slices = np.array([training_array[i] for i in idx])\n",
    "\n",
    "        # Generate fake images\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_slices = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_slices, np.ones((batch_size, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_slices, np.zeros((batch_size, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        print(f\"D Loss: {d_loss[0]}, G Loss: {g_loss[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'tanmay/brain_slices/'\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for key in keys:\n",
    "        brain_array = load_images(bucket_name=bucket, folder_path=folder_path, folder_suffix=key)\n",
    "        print(\"Training Gan now:\")\n",
    "        train_gan(generator=chemocraft_generator, latent_dim=dim, discriminator=chemocraft_discriminator, gan=chemocraft_gan, training_array=brain_array, batch_size=5)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
