{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "de8e0dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (1.35.44)\n",
      "Requirement already satisfied: nibabel in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (5.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: torch in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: pillow in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.44 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from boto3) (1.35.44)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from boto3) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from nibabel) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from nibabel) (4.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from botocore<1.36.0,>=1.35.44->boto3) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\grnpr\\anaconda3\\envs\\chemocraft\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages for the notebook\n",
    "\n",
    "%pip install boto3 nibabel numpy matplotlib torch torchvision torchaudio pillow tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1950f2bf-d1fd-4c35-b6b7-8318c816c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprint 1: Reading NII files from S3 and saving PNGs\n",
    "\n",
    "import boto3\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import io\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Initialize S3 resource and specify bucket and folder details\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'chemocraft-data'\n",
    "folder_path = 'MICCAI_BraTS2020_TrainingData/'\n",
    "# folder_path = 'Data/BraTS20_Training_369 copy/'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "def plot_slice(data, crop, slice_idx, filename):\n",
    "    # Crop the specified slice\n",
    "    slice_2d = data[:, :, slice_idx]\n",
    "    cropped_slice = slice_2d[crop[0][0]:crop[0][1], crop[1][0]:crop[1][1]]\n",
    "    \n",
    "    # Display the cropped slice with matplotlib\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cropped_slice, cmap='gray')\n",
    "    plt.title(f'Slice {slice_idx} of {filename}')\n",
    "    plt.axis('off')  # Hide axes for cleaner display\n",
    "    plt.show()\n",
    "\n",
    "def savePNG(data, crop, filename):    \n",
    "    # Prepare directory structure\n",
    "    fileWOext = filename.split(\".\")[0]\n",
    "    TrainingCount = fileWOext.split(\"_\")[-2]\n",
    "    ScanType = fileWOext.split(\"_\")[-1]\n",
    "    slice_path = f\"brain_slices/{TrainingCount}/{ScanType}/\"\n",
    "    print(f\"Saving in directory: {slice_path}\")\n",
    "\n",
    "    # Iterate through each slice in the Z-Dimiension data and save as PNG\n",
    "    for slice_idx in range(data.shape[2]):\n",
    "        # Crop each slice\n",
    "        slice_2d = data[:, :, slice_idx]\n",
    "        cropped_slice = slice_2d[crop[0][0]:crop[0][1], crop[1][0]:crop[1][1]]\n",
    "        png_filename = f\"{slice_path}{slice_idx}.png\"\n",
    "        \n",
    "        # Local Saving\n",
    "        # try:\n",
    "        #     # Create directories as needed and save each slice\n",
    "        #     os.makedirs(slice_path, exist_ok=True)\n",
    "        #     mpimg.imsave(png_filename, cropped_slice, cmap='gray')\n",
    "        # except Exception as e:\n",
    "        #     print(f\"ERROR: directory could not be made due to {e}\")\n",
    "        \n",
    "        # Upload each PNG to S3\n",
    "        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_png:\n",
    "            mpimg.imsave(temp_png.name, cropped_slice, cmap='gray')\n",
    "            temp_png.flush()\n",
    "            temp_png.seek(0)\n",
    "            temp_png_name = temp_png.name  # Store the name to use it after the file is closed\n",
    "\n",
    "        try:\n",
    "            s3.Bucket(bucket_name).upload_file(temp_png_name, f\"Akshay/{png_filename}\")\n",
    "            os.remove(temp_png_name)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not upload or delete temporary PNG file due to {e}\")\n",
    "\n",
    "def render_nii_from_s3(filename, path):\n",
    "    print(f\"Fetching file: {filename}\")\n",
    "\n",
    "    try:\n",
    "        obj = bucket.Object(path + filename)\n",
    "        file_stream = io.BytesIO(obj.get()['Body'].read())\n",
    "    except s3.meta.client.exceptions.NoSuchKey as e:\n",
    "        print(f\"ERROR: The specified key does not exist: {path + filename}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix='.nii', delete=False) as temp_file:  # Prevent auto-deletion\n",
    "        temp_file.write(file_stream.getvalue())\n",
    "        temp_file.flush()\n",
    "\n",
    "        temp_file_path = temp_file.name\n",
    "        print(f\"Temporary file created: {temp_file_path}\")\n",
    "\n",
    "    try:\n",
    "        img = nib.load(temp_file_path)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        print(f\"Data shape for {filename}: {data.shape}\")\n",
    "        \n",
    "        if data.size == 0:\n",
    "            print(f\"No data found in {filename}\")\n",
    "            return\n",
    "\n",
    "        # Define crop dimensions\n",
    "        cropleft = 25\n",
    "        cropright = data.shape[0] - 15\n",
    "        cropbottom = data.shape[1] - 40\n",
    "        croptop = 40\n",
    "        \n",
    "        crop = np.array([[croptop, cropbottom], [cropleft, cropright]])\n",
    "        \n",
    "        # Save the PNGs and plot a sample slice\n",
    "        savePNG(data, crop, filename)\n",
    "        \n",
    "        # slice_idx = 88  # Choose a slice index for sample display\n",
    "        # plot_slice(data, crop, slice_idx, filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {filename}: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(temp_file_path)\n",
    "            print(f\"Deleted temporary file: {temp_file_path}\")\n",
    "        except OSError as cleanup_error:\n",
    "            print(f\"Error deleting temp file: {cleanup_error}\")\n",
    "\n",
    "def find_and_render_nii_files():\n",
    "    found_files = False\n",
    "\n",
    "    subfolders = set()  # use a set to ensure unique subfolder names\n",
    "    for obj in bucket.objects.filter(Prefix=folder_path):\n",
    "        # Get the path after the 'Data/' prefix and split it by '/'\n",
    "        path_parts = obj.key[len(folder_path):].split('/')\n",
    "        \n",
    "        # Check if there's at least one part (indicating a subfolder)\n",
    "        if len(path_parts) > 1:\n",
    "            subfolders.add(f'{path_parts[0]}/')  # Add the subfolder name\n",
    "            \n",
    "    subfolders = sorted(subfolders)\n",
    "\n",
    "    print(f\"Root Directory: {folder_path.split('/')[0]}\")\n",
    "    # print(subfolders)\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        path = folder_path + subfolder\n",
    "        print(f\"Reading S3 in {path}\")\n",
    "        for obj in bucket.objects.filter(Prefix=path):\n",
    "            if obj.key.endswith('.nii'):\n",
    "                print(f\"path: {path}\")\n",
    "                found_files = True\n",
    "                filename = obj.key.split('/')[-1]  # Extract filename from path\n",
    "                print(f\"Found .nii file: {filename}\")\n",
    "                render_nii_from_s3(filename, path)\n",
    "\n",
    "    if not found_files:\n",
    "        print(f\"No .nii files found in the folder {folder_path}\")\n",
    "\n",
    "# Main function\n",
    "# find_and_render_nii_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "869e03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprint 2: GAN for Brain MRI Generation\n",
    "\n",
    "import io\n",
    "from io import BytesIO\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from tensorflow.keras.utils import Sequence # type: ignore # type: ignore\n",
    "from keras.preprocessing.image import img_to_array, load_img # type: ignore\n",
    "\n",
    "# Initialize S3 resource and specify bucket and folder details\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'chemocraft-data'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "folder_prefix = \"Akshay/brain_slices/\"\n",
    "\n",
    "def load_images_from_s3(bucket, folder_prefix):\n",
    "    print(f\"Loading images from S3 bucket: {bucket_name}/{folder_prefix}\")\n",
    "    images = []\n",
    "    for obj in bucket.objects.filter(Prefix=folder_prefix):\n",
    "        if obj.key.endswith('.png'):\n",
    "            file_stream = io.BytesIO(obj.get()['Body'].read())\n",
    "            image = load_img(file_stream, target_size=(200, 160), color_mode='grayscale')\n",
    "            image = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# Generator Model\n",
    "def build_generator(latent_dim=100, output_shape=(200, 160, 1)):\n",
    "    \"\"\"\n",
    "    Builds the generator model for a GAN.\n",
    "    \n",
    "    Parameters:\n",
    "    latent_dim (int): The size of the input latent vector.\n",
    "    output_shape (tuple): The desired shape of the generated images (height, width, channels).\n",
    "    \n",
    "    Returns:\n",
    "    A compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name=\"Generator\")\n",
    "    print(\"Building Generator Model\")\n",
    "    \n",
    "    # Input layer\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "    model.add(layers.Input(shape=(latent_dim,)))\n",
    "    model.add(layers.Dense(128 * 25 * 20, activation=\"relu\"))\n",
    "    model.add(layers.Reshape((25, 20, 128)))\n",
    "    \n",
    "    # Transposed convolutional layers to upsample\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "    # model.add(layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"))  \n",
    "    # model.add(layers.Conv2DTranspose(8, kernel_size=4, strides=4, padding=\"same\", activation=\"relu\"))  \n",
    "    model.add(layers.Conv2D(8, kernel_size=3, padding=\"same\", activation=\"tanh\"))\n",
    "    model.add(layers.Conv2DTranspose(output_shape[2], kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Activation(\"tanh\"))\n",
    "    # model.summary()\n",
    "\n",
    "    # model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "    model.compile(Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "# Discriminator Model\n",
    "def build_discriminator(input_shape):\n",
    "    \"\"\"\n",
    "    Builds the discriminator model for a GAN.\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): The shape of the input images (height, width, channels).\n",
    "    \n",
    "    Returns:\n",
    "    A compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name=\"Discriminator\")\n",
    "    print(\"Building Discriminator Model\")\n",
    "    \n",
    "    # Input layer\n",
    "    print(f\"Input shape: {input_shape}\")\n",
    "    \n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Conv2D(32, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.Conv2D(32, kernel_size=4, strides=2, padding=\"same\", input_shape=input_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Flatten and output layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    # model.summary()\n",
    "    \n",
    "    model.compile(Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "    # model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "    return model\n",
    "\n",
    "# GAN Model\n",
    "def compile_gan(generator, discriminator, latent_dim):\n",
    "    # Make the discriminator layers non-trainable\n",
    "    print(\"Building GAN Model\")\n",
    "    \n",
    "    z = layers.Input(shape=(latent_dim,))\n",
    "    img = generator(z)\n",
    "    discriminator.trainable = False\n",
    "    validity = discriminator(img) \n",
    "    \n",
    "    # Compile the combined GAN model\n",
    "    gan = keras.Model(z, validity, name=\"GAN\")\n",
    "    gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "    gan._name = \"GAN\"\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f8ab12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Generator Model\n",
      "Output shape: (200, 160, 1)\n",
      "Building Discriminator Model\n",
      "Input shape: (200, 160, 1)\n",
      "Building GAN Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Generator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Generator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_182            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_183            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_184            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_104 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m)          │     \u001b[38;5;34m6,464,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_58 (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_182            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_183            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_189 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │         \u001b[38;5;34m4,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_184            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │           \u001b[38;5;34m129\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_109 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,690,121</span> (25.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,690,121\u001b[0m (25.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,690,121</span> (25.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,690,121\u001b[0m (25.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16640</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,641</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_190 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_191 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m16,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_154 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_192 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_155 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_193 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_156 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_49 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16640\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m16,641\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,633</span> (772.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m197,633\u001b[0m (772.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,633</span> (772.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m197,633\u001b[0m (772.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GAN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"GAN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Generator (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,690,121</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Discriminator (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,633</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_155 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Generator (\u001b[38;5;33mSequential\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │     \u001b[38;5;34m6,690,121\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Discriminator (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m197,633\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,887,754</span> (26.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,887,754\u001b[0m (26.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,690,121</span> (25.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,690,121\u001b[0m (25.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,633</span> (772.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m197,633\u001b[0m (772.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate models\n",
    "latent_dim = 100\n",
    "img_shape = (200, 160, 1)\n",
    "generator = build_generator(latent_dim=latent_dim, output_shape=img_shape)\n",
    "discriminator = build_discriminator(input_shape=img_shape)\n",
    "gan = compile_gan(generator, discriminator, latent_dim)\n",
    "\n",
    "# Display model summaries\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ddcb97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from S3 bucket: chemocraft-data/Akshay/brain_slices/320/\n",
      "Training GAN...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;66;03m# Print loss values\u001b[39;00m\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, G Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m train_gan(generator, discriminator, gan, latent_dim, epochs, batch_size)\n",
      "Cell \u001b[1;32mIn[131], line 27\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, gan, latent_dim, epochs, batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((half_batch, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train discriminator\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(real_images, real_labels)\n\u001b[0;32m     28\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_images, fake_labels)\n\u001b[0;32m     29\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (d_loss_real \u001b[38;5;241m+\u001b[39m d_loss_fake)\n",
      "File \u001b[1;32mc:\\Users\\grnpr\\anaconda3\\envs\\chemocraft\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:549\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 549\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(data())\n\u001b[0;32m    550\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\grnpr\\anaconda3\\envs\\chemocraft\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\grnpr\\anaconda3\\envs\\chemocraft\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    122\u001b[0m     one_step_on_data, args\u001b[38;5;241m=\u001b[39m(data,)\n\u001b[0;32m    123\u001b[0m )\n\u001b[0;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    125\u001b[0m     outputs,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    128\u001b[0m )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\grnpr\\anaconda3\\envs\\chemocraft\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:108\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(data)\n",
      "File \u001b[1;32mc:\\Users\\grnpr\\anaconda3\\envs\\chemocraft\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:61\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     53\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[0;32m     55\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m     56\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     60\u001b[0m )\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_tracker\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[0;32m     62\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 50\n",
    "batch_size = 155*4\n",
    "half_batch = batch_size // 2\n",
    "\n",
    "def train_gan(generator, discriminator, gan, latent_dim, epochs, batch_size):\n",
    "    # Load images from S3\n",
    "    s3 = boto3.resource('s3')   \n",
    "    bucket = s3.Bucket('chemocraft-data')\n",
    "    images = load_images_from_s3(bucket, 'Akshay/brain_slices/320/')\n",
    "\n",
    "    half_batch = 64//2\n",
    "    \n",
    "    print(\"Training GAN...\")\n",
    "    for epoch in range(epochs):\n",
    "        # Train discriminator with real images\n",
    "        idx = np.random.randint(0, images.shape[0], half_batch)\n",
    "        real_images = images[idx]\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        \n",
    "        # Generate fake images\n",
    "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "        fake_images = generator.predict(noise)\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "        \n",
    "        # Train discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        \n",
    "        # Update discriminator loss tracker\n",
    "        if hasattr(discriminator, 'metrics') and discriminator.metrics:\n",
    "            for metric in discriminator.metrics:\n",
    "                if hasattr(metric, 'update_state'):\n",
    "                    metric.update_state(d_loss)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        misleading_labels = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, misleading_labels)\n",
    "        \n",
    "        # Update generator loss tracker\n",
    "        if hasattr(gan, 'metrics') and gan.metrics:\n",
    "            for metric in gan.metrics:\n",
    "                if hasattr(metric, 'update_state'):\n",
    "                    metric.update_state(g_loss)\n",
    "        \n",
    "        # Print loss values\n",
    "        print(f\"{epoch+1}/{epochs}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
    "        \n",
    "train_gan(generator, discriminator, gan, latent_dim, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_image(generator, latent_dim, num_slices=150):\n",
    "    noise = np.random.normal(0, 1, (num_slices, latent_dim))\n",
    "    generated_slices = generator.predict(noise)\n",
    "    generated_3d_image = np.stack(generated_slices, axis=0)  # Shape: (num_slices, 200, 160)\n",
    "    return generated_3d_image\n",
    "\n",
    "# generated_3d_image = generate_3d_image(generator, latent_dim=100, num_slices=150)\n",
    "\n",
    "# Display the generated 3D image\n",
    "# fig, axs = plt.subplots(10, 15, figsize=(15, 10))\n",
    "# cnt = 0\n",
    "# for i in range(10):\n",
    "#     for j in range(15):\n",
    "#         axs[i, j].imshow(generated_3d_image[cnt, :, :, 0], cmap='gray')\n",
    "#         axs[i, j].axis('off')\n",
    "#         cnt += 1\n",
    "# plt.show()\n",
    "\n",
    "# Save the models\n",
    "generator.save('generator_model.h5')\n",
    "discriminator.save('discriminator_model.h5')\n",
    "gan.save('gan_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
